---
title: "test1"
output: html_document
date: "2023-09-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Design mock experiment. 

```{r}
set.seed(123)
n_genes <- 1000
patient <- rep(c("A", "B", "C"), 2)
condition <- rep(c("Control", "Treated"), each = 3)
coldata <- data.frame(patient = patient,
                      condition = condition)
counts <- rpois(nrow(coldata)*n_genes,
                lambda = runif(n_genes, 10, 500))|>
  matrix(ncol = nrow(coldata))
colnames(counts) <- paste(condition, patient, sep = ".")

head(counts)
```
Now we want to add some patient-to-patient variation, to make accounting for patient ID worthwhile. We make adjustments to each gene separately, rather than scale the whole library for any of that patients, as we are dealing with compositional data after all (library scaling is removed downstream). 


```{r}
set.seed(123)
patient_scaling <- runif(3*n_genes, 0, 2)|>
  rep(2)|>
  matrix(ncol = nrow(coldata))

head(patient_scaling)
```
See how the columns are the same in the same patient (different treatment). This is also seen by the correlation matrix. 

```{r}
cor(patient_scaling)
```

Apply this scaling matrix to the count data: 

```{r}
counts_scaled <- counts*patient_scaling |> round()
rm(counts)

head(counts_scaled)
```

We should be able to see the patients cluster by PCA now. 

```{r}
library(edgeR)

plotMDS(counts_scaled, col = as.factor(coldata$patient),
        pch = as.numeric(as.factor(coldata$condition)))
legend("top", legend = paste(condition, patient, sep = "."),
       col = as.factor(coldata$patient), 
       pch = as.numeric(as.factor(coldata$condition)),
       ncol = 2)
```

Next, we add the effect of the treatment, which will be consistent across the patients. (unless we want interactions...).

We implement this by only adjusting the treated patients. 


```{r}
treatment_scaling <- runif(n_genes, 0, 2)|>
  rep(3)|>
  matrix(ncol = length(which(coldata$condition == "Treated")))
  
head(treatment_scaling)
```


```{r}
counts_treated <- counts_scaled
rm(counts_scaled)

counts_treated[,4:6] <- counts_treated[,4:6]*treatment_scaling |>
  round()

head(counts_treated)
```

```{r}
plotMDS(counts_treated, col = as.factor(coldata$patient),
        pch = as.numeric(as.factor(coldata$condition)))
legend("topleft", legend = paste(condition, patient, sep = "."),
       col = as.factor(coldata$patient), 
       pch = as.numeric(as.factor(coldata$condition)),
       ncol = 2)
```


If we wanted to remove the patient variable, use limma: 

```{r}
test_rm <- removeBatchEffect(counts_treated,
                             batch = coldata$patient,
                             design = model.matrix(~ condition))

plotMDS(test_rm, col = as.factor(coldata$patient),
        pch = as.numeric(as.factor(coldata$condition)))
legend("top", legend = paste(condition, patient, sep = "."),
       col = as.factor(coldata$patient), 
       pch = as.numeric(as.factor(coldata$condition)),
       ncol = 2)
```

Or indeed the treatment variable: 

```{r}
test_rm <- removeBatchEffect(counts_treated,
                             batch = coldata$condition,
                             design = model.matrix(~ patient))

plotMDS(test_rm, col = as.factor(coldata$patient),
        pch = as.numeric(as.factor(coldata$condition)))
legend("bottom", legend = paste(condition, patient, sep = "."),
       col = as.factor(coldata$patient), 
       pch = as.numeric(as.factor(coldata$condition)),
       ncol = 2)
```

Notice the difference when comparing to the data before the treatment effect (counts scaled). 


Now use edgeR. 

Define the model. Here we decide which factors are important.  

```{r}
design <- model.matrix(~ 0 + patient + condition)
# by default what the nextflow pipeline uses
# design <- model.matrix(~ 0 + condition) 
design
```



```{r}
group <- factor(paste0(condition, ".", patient))
y <- DGEList(counts_treated, group=group)

# library normalisation not necessary in this example - no 
# scaling was done when simulating the data
# y <- normLibSizes(y)

y <- estimateDisp(y, design, robust=TRUE)
plotBCV(y)
```

Not sure if dispersion estimation works in this example.. 


Fit the model for each gene using quasi-likelihood

```{r}
fit <- glmQLFit(y, design, robust=TRUE)
plotQLDisp(fit)
```

# How the design is passed downstream 

Test different experiment designs. 

First, the simplest design - no patient ID. 

```{r}
design <- model.matrix(~ condition)
y <- DGEList(counts_treated, group=group)
y <- estimateDisp(y, design, robust=TRUE)
fit <- glmQLFit(y, design, robust=TRUE)

plotBCV(y)
plotQLDisp(fit)

qlf <- glmQLFTest(fit)
edger_res <- topTags(qlf, n=nrow(y), sort.by="PValue")[[1]]
head(edger_res)

length(which(edger_res$PValue < 0.05 & edger_res$logFC > 0))
length(which(edger_res$PValue < 0.05 & edger_res$logFC < 0))

plotMD(qlf)
abline(h=c(-1,1), col="blue")
```



```{r}
design <- model.matrix(~ 0 + patient + condition)
y <- DGEList(counts_treated, group=group)
y <- estimateDisp(y, design, robust=TRUE)
fit <- glmQLFit(y, design, robust=TRUE)

plotBCV(y)
plotQLDisp(fit)

qlf <- glmQLFTest(fit, coef = 4)
edger_res <- topTags(qlf, n=nrow(y), sort.by="PValue")[[1]]
head(edger_res)

length(which(edger_res$PValue < 0.05 & edger_res$logFC > 0))
length(which(edger_res$PValue < 0.05 & edger_res$logFC < 0))

plotMD(qlf)
abline(h=c(-1,1), col="blue")
```




